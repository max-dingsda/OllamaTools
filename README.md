# ğŸ§  OllamaTools for ComfyUI

> *â€œTo be honest, most LLM nodes in ComfyUI were just too complicated for me.  
> So I built the kind of tools I wish I had when I started.â€*

ComfyUI has powerful capabilities for working with local LLMs via [Ollama](https://ollama.com), but many existing nodes are complex, poorly documented, or difficult to use for newcomers, or to be honest, people like me

**This project makes local LLMs easy to use for prompt enhancement and image captioning â€“**  
No API keys. No external tools. No headache.

---

## ğŸ§© Included Nodes

### ğŸ”¹ Ollama Prompt Booster

Improves a basic text prompt using a local language model like Zephyr or DeepSeek.  
Turns short ideas into more vivid, descriptive prompts for text-to-image generation.

âœ… Supports the following models:
- `zephyr:7b-beta`
- `deepseek-r1:8b`
- `llama3.2:latest`
- `mistral:latest`

---

### ğŸ”¹ Ollama Pic Describer

Takes an image and returns a prompt-like description.  
Great for `img2img`, ControlNet reruns, prompt recovery, or inspiration.  
Supports style options like `cinematic`, `poetic`, or `nsfw`.

âœ… Supports the following models:
- `llava:latest`
- `moondream:latest`

---

## ğŸš€ Examples

### âœï¸ Prompt Booster

Input:
```text
woman on a balcony, sunset, elegant
```

Output:
```text
An elegant woman gazes over the cityscape from a golden-lit balcony, her dress flowing in the evening breezeâ€¦
```

---

### ğŸ–¼ï¸ Pic Describer

Given this image:  
*(Insert image of woman on a couch)*

Returns a prompt like:
```text
A beautiful woman lounges barefoot on a white sofa, her shirt loose and airy, lit by soft studio lightingâ€¦
```

---

## ğŸ’» Installation

1. Install [Ollama](https://ollama.com) and make sure it's running locally
2. Clone this repo into your `ComfyUI/custom_nodes` folder:

```bash
git clone https://github.com/YOURNAME/ComfyUI-OllamaTools.git
```

3. (Optional) Install Python dependencies:

```bash
pip install -r requirements.txt
```

4. Launch ComfyUI and start building!

---

## ğŸ”§ Model Setup

You can pull the models you need with:

```bash
ollama pull zephyr:7b-beta
ollama pull deepseek-r1:8b
ollama pull llava:latest
ollama pull moondream:latest
```

Only models you're using need to be installed.

---

## ğŸ§  Requirements

- Python 3.10+
- ComfyUI
- Ollama (running locally)
- Python libraries:
  - `requests`
  - `Pillow`

---

## ğŸªª License

MIT â€“ use freely, contribute gladly, no need to pretend you wrote it ğŸ˜‰

---

## ğŸ’¬ About

This project was built out of necessity â€“ and some self-deprecating humor.  
I wanted LLM features that "just work" inside ComfyUI.

If you're the same: welcome aboard.
